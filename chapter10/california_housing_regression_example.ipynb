{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.7452 - val_loss: 0.5588\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4770 - val_loss: 0.4773\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4416 - val_loss: 0.4368\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4230 - val_loss: 0.4273\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4111 - val_loss: 0.3825\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3989 - val_loss: 0.3725\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3963 - val_loss: 0.3741\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3875 - val_loss: 0.3696\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3923 - val_loss: 0.4220\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3814 - val_loss: 0.3563\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3880 - val_loss: 0.3582\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3792 - val_loss: 0.3530\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3714 - val_loss: 0.3461\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3702 - val_loss: 0.3573\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3668 - val_loss: 0.3450\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3658 - val_loss: 0.3454\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3709 - val_loss: 0.3417\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3762 - val_loss: 0.3370\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3575 - val_loss: 0.4039\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3566 - val_loss: 0.3334\n",
      "5160/5160 [==============================] - 0s 11us/sample - loss: 0.3915\n",
      "[[1.6084081]\n",
      " [1.4791679]\n",
      " [3.6024153]]\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 1.3378 - val_loss: 1.5405\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5069 - val_loss: 0.3992\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4021 - val_loss: 0.3868\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3804 - val_loss: 0.3619\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3687 - val_loss: 0.4853\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3696 - val_loss: 0.5359\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3699 - val_loss: 0.6316\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3689 - val_loss: 0.3746\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3363 - val_loss: 0.3250\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3333 - val_loss: 0.4240\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3276 - val_loss: 0.4031\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3257 - val_loss: 0.6545\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3511 - val_loss: 0.6727\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3459 - val_loss: 0.3832\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3140 - val_loss: 0.4030\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3145 - val_loss: 0.3171\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3047 - val_loss: 0.3000\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3016 - val_loss: 0.3460\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3022 - val_loss: 0.3369\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3039 - val_loss: 0.3044\n",
      "5160/5160 [==============================] - 0s 13us/sample - loss: 0.3455\n",
      "[[1.605746  ]\n",
      " [0.96955204]\n",
      " [3.7522295 ]]\n"
     ]
    }
   ],
   "source": [
    "# Wide and deep neural net.\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model2 = keras.Model(inputs=[input_], outputs=[output])\n",
    "model2.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(model2.summary())\n",
    "history2 = model2.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test2 = model2.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model2.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 2.0348 - val_loss: 1.0947\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.7172 - val_loss: 0.6339\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.6147 - val_loss: 0.5724\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5818 - val_loss: 0.5471\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5619 - val_loss: 0.5308\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5465 - val_loss: 0.5174\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5341 - val_loss: 0.5055\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5233 - val_loss: 0.4955\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5138 - val_loss: 0.4874\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5054 - val_loss: 0.4763\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4983 - val_loss: 0.4703\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4916 - val_loss: 0.4670\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4856 - val_loss: 0.4564\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4804 - val_loss: 0.4598\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4760 - val_loss: 0.4471\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4716 - val_loss: 0.4473\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4677 - val_loss: 0.4403\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4642 - val_loss: 0.4388\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4609 - val_loss: 0.4362\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4571 - val_loss: 0.4316\n",
      "5160/5160 [==============================] - 0s 16us/sample - loss: 0.4881\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model3 = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model3.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model3.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model3.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model3.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7ff490229b70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7ff490229cc0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7ff490229ba8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7ff490229f98>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x7ff55820a2b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7ff490222828>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7ff490229cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.get_layer('dense_5') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 23us/sample - loss: 0.4981 - main_output_loss: 0.4637 - aux_output_loss: 0.7973\n",
      "0.4981348545514336 0.46374595 0.7973324\n",
      "[[1.9625449]\n",
      " [1.5608535]\n",
      " [3.0432026]] [[2.3038797]\n",
      " [1.7771248]\n",
      " [2.6100736]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(\"model4.hdf5\"):\n",
    "    model4 = keras.models.load_model(\"model4.hdf5\")\n",
    "else:\n",
    "    main_output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "    aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "    model4 = keras.Model(inputs=[input_A, input_B], outputs=[main_output, aux_output])\n",
    "    model4.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "    history = model4.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                        validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model4.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model4.predict([X_new_A, X_new_B])\n",
    "print(total_loss, main_loss, aux_loss)\n",
    "print(y_pred_main, y_pred_aux)\n",
    "if not os.path.exists(\"model4.hdf5\"):\n",
    "    model4.save(\"model4.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 2.6605 - output_1_loss: 2.3883 - output_2_loss: 5.1018 - val_loss: 3.1175 - val_output_1_loss: 2.8633 - val_output_2_loss: 5.3986\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 1.0803 - output_1_loss: 0.8150 - output_2_loss: 3.4674 - val_loss: 1.2949 - val_output_1_loss: 0.9618 - val_output_2_loss: 4.2915\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.8427 - output_1_loss: 0.6745 - output_2_loss: 2.3572 - val_loss: 0.9592 - val_output_1_loss: 0.6801 - val_output_2_loss: 3.4682\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.7407 - output_1_loss: 0.6212 - output_2_loss: 1.8142 - val_loss: 0.8397 - val_output_1_loss: 0.6151 - val_output_2_loss: 2.8600\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6876 - output_1_loss: 0.5917 - output_2_loss: 1.5490 - val_loss: 0.7755 - val_output_1_loss: 0.5978 - val_output_2_loss: 2.3740\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6552 - output_1_loss: 0.5705 - output_2_loss: 1.4159 - val_loss: 0.7327 - val_output_1_loss: 0.5862 - val_output_2_loss: 2.0526\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6314 - output_1_loss: 0.5524 - output_2_loss: 1.3409 - val_loss: 0.6908 - val_output_1_loss: 0.5657 - val_output_2_loss: 1.8162\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6133 - output_1_loss: 0.5377 - output_2_loss: 1.2925 - val_loss: 0.6758 - val_output_1_loss: 0.5722 - val_output_2_loss: 1.6100\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5966 - output_1_loss: 0.5234 - output_2_loss: 1.2548 - val_loss: 0.6451 - val_output_1_loss: 0.5514 - val_output_2_loss: 1.4881\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5817 - output_1_loss: 0.5101 - output_2_loss: 1.2247 - val_loss: 0.6294 - val_output_1_loss: 0.5448 - val_output_2_loss: 1.3900\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5684 - output_1_loss: 0.4986 - output_2_loss: 1.1969 - val_loss: 0.6023 - val_output_1_loss: 0.5227 - val_output_2_loss: 1.3195\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5569 - output_1_loss: 0.4888 - output_2_loss: 1.1703 - val_loss: 0.5879 - val_output_1_loss: 0.5135 - val_output_2_loss: 1.2578\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5459 - output_1_loss: 0.4793 - output_2_loss: 1.1456 - val_loss: 0.5679 - val_output_1_loss: 0.4959 - val_output_2_loss: 1.2162\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5366 - output_1_loss: 0.4715 - output_2_loss: 1.1215 - val_loss: 0.5554 - val_output_1_loss: 0.4865 - val_output_2_loss: 1.1760\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5279 - output_1_loss: 0.4644 - output_2_loss: 1.0987 - val_loss: 0.5444 - val_output_1_loss: 0.4783 - val_output_2_loss: 1.1399\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5197 - output_1_loss: 0.4580 - output_2_loss: 1.0753 - val_loss: 0.5357 - val_output_1_loss: 0.4723 - val_output_2_loss: 1.1055\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5121 - output_1_loss: 0.4519 - output_2_loss: 1.0527 - val_loss: 0.5248 - val_output_1_loss: 0.4631 - val_output_2_loss: 1.0804\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5053 - output_1_loss: 0.4468 - output_2_loss: 1.0311 - val_loss: 0.5151 - val_output_1_loss: 0.4554 - val_output_2_loss: 1.0524\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4992 - output_1_loss: 0.4426 - output_2_loss: 1.0094 - val_loss: 0.5070 - val_output_1_loss: 0.4488 - val_output_2_loss: 1.0296\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4931 - output_1_loss: 0.4381 - output_2_loss: 0.9873 - val_loss: 0.5024 - val_output_1_loss: 0.4469 - val_output_2_loss: 1.0006\n",
      "5160/5160 [==============================] - 0s 18us/sample - loss: 0.4959 - output_1_loss: 0.4434 - output_2_loss: 0.9752\n",
      "0.49589378223862757 0.44343236 0.9751759\n",
      "[[1.7571504]\n",
      " [2.8326354]\n",
      " [1.1302142]] [[2.0910418]\n",
      " [2.3024797]\n",
      " [1.6514804]]\n"
     ]
    }
   ],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model5 = WideAndDeepModel()\n",
    "model5.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "main_output, aux_output = model5(inputs=[input_A, input_B])\n",
    "history = model5.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                     validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model5.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model5.predict([X_new_A, X_new_B])\n",
    "print(total_loss, main_loss, aux_loss)\n",
    "print(y_pred_main, y_pred_aux)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
