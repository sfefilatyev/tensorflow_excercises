{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.8362 - val_loss: 3.8631\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.5114 - val_loss: 15.3588\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4986 - val_loss: 2.0926\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4236 - val_loss: 0.4205\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3997 - val_loss: 0.3929\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3893 - val_loss: 0.3990\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3837 - val_loss: 0.3812\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3790 - val_loss: 0.3861\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3731 - val_loss: 0.3976\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3699 - val_loss: 0.3938\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3667 - val_loss: 0.3906\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3659 - val_loss: 0.3925\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3627 - val_loss: 0.3955\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3637 - val_loss: 0.3975\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3577 - val_loss: 0.4033\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3559 - val_loss: 0.3917\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3537 - val_loss: 0.3850\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3523 - val_loss: 0.3909\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3538 - val_loss: 0.3754\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3495 - val_loss: 0.3750\n",
      "5160/5160 [==============================] - 0s 12us/sample - loss: 0.3581\n",
      "[[1.555022 ]\n",
      " [2.7669668]\n",
      " [1.3924704]]\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 1.5019 - val_loss: 0.5925\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4556 - val_loss: 0.4570\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3961 - val_loss: 1.0832\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3844 - val_loss: 3.4890\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3927 - val_loss: 0.5706\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3686 - val_loss: 0.4989\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3548 - val_loss: 0.3751\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3517 - val_loss: 1.0428\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3500 - val_loss: 0.5910\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3500 - val_loss: 1.4868\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3389 - val_loss: 2.0742\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3497 - val_loss: 1.4690\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3416 - val_loss: 0.4788\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3252 - val_loss: 0.4269\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3286 - val_loss: 0.3766\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3225 - val_loss: 0.8428\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3234 - val_loss: 0.7195\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3143 - val_loss: 1.6687\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3211 - val_loss: 1.8921\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3198 - val_loss: 1.2869\n",
      "5160/5160 [==============================] - 0s 12us/sample - loss: 0.3122\n",
      "[[1.7834945]\n",
      " [2.7745056]\n",
      " [1.5127283]]\n"
     ]
    }
   ],
   "source": [
    "# Wide and deep neural net.\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model2 = keras.Model(inputs=[input_], outputs=[output])\n",
    "model2.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(model2.summary())\n",
    "history2 = model2.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test2 = model2.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model2.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 1.8703 - val_loss: 0.9025\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.6623 - val_loss: 0.6181\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5913 - val_loss: 0.5758\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5504 - val_loss: 0.5392\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5220 - val_loss: 0.5177\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5006 - val_loss: 0.4995\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4846 - val_loss: 0.4877\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4715 - val_loss: 0.4710\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4614 - val_loss: 0.4619\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4534 - val_loss: 0.4560\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4455 - val_loss: 0.4510\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4401 - val_loss: 0.4463\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4348 - val_loss: 0.4422\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4305 - val_loss: 0.4390\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4262 - val_loss: 0.4289\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4234 - val_loss: 0.4333\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4205 - val_loss: 0.4292\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4178 - val_loss: 0.4423\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4164 - val_loss: 0.4587\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4124 - val_loss: 0.4180\n",
      "5160/5160 [==============================] - 0s 14us/sample - loss: 0.4220\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model3 = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model3.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model3.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model3.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model3.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f1bd8725be0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f1bd8725cf8>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f1bd8725c18>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f1bd8725f98>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x7f1bd8725eb8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f1bd87286a0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f1bd8725cf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.get_layer('dense_5') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 1.5473 - main_output_loss: 1.3725 - aux_output_loss: 3.1164 - val_loss: 1.4073 - val_main_output_loss: 1.3393 - val_aux_output_loss: 2.0133\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.6807 - main_output_loss: 0.5930 - aux_output_loss: 1.4683 - val_loss: 0.6373 - val_main_output_loss: 0.5824 - val_aux_output_loss: 1.1306\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5707 - main_output_loss: 0.5210 - aux_output_loss: 1.0184 - val_loss: 0.5640 - val_main_output_loss: 0.5234 - val_aux_output_loss: 0.9280\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5347 - main_output_loss: 0.4951 - aux_output_loss: 0.8909 - val_loss: 0.5513 - val_main_output_loss: 0.5144 - val_aux_output_loss: 0.8853\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5159 - main_output_loss: 0.4791 - aux_output_loss: 0.8467 - val_loss: 0.5509 - val_main_output_loss: 0.5148 - val_aux_output_loss: 0.8748\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5040 - main_output_loss: 0.4684 - aux_output_loss: 0.8263 - val_loss: 0.5498 - val_main_output_loss: 0.5152 - val_aux_output_loss: 0.8617\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4942 - main_output_loss: 0.4588 - aux_output_loss: 0.8129 - val_loss: 0.5450 - val_main_output_loss: 0.5114 - val_aux_output_loss: 0.8465\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4866 - main_output_loss: 0.4519 - aux_output_loss: 0.7998 - val_loss: 0.5413 - val_main_output_loss: 0.5086 - val_aux_output_loss: 0.8343\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4803 - main_output_loss: 0.4458 - aux_output_loss: 0.7897 - val_loss: 0.5617 - val_main_output_loss: 0.5325 - val_aux_output_loss: 0.8241\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4748 - main_output_loss: 0.4408 - aux_output_loss: 0.7800 - val_loss: 0.5530 - val_main_output_loss: 0.5245 - val_aux_output_loss: 0.8095\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4701 - main_output_loss: 0.4365 - aux_output_loss: 0.7719 - val_loss: 0.5474 - val_main_output_loss: 0.5195 - val_aux_output_loss: 0.7960\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4657 - main_output_loss: 0.4327 - aux_output_loss: 0.7628 - val_loss: 0.5324 - val_main_output_loss: 0.5046 - val_aux_output_loss: 0.7812\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4620 - main_output_loss: 0.4295 - aux_output_loss: 0.7543 - val_loss: 0.5592 - val_main_output_loss: 0.5353 - val_aux_output_loss: 0.7741\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4582 - main_output_loss: 0.4262 - aux_output_loss: 0.7453 - val_loss: 0.5206 - val_main_output_loss: 0.4943 - val_aux_output_loss: 0.7567\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4553 - main_output_loss: 0.4239 - aux_output_loss: 0.7371 - val_loss: 0.5477 - val_main_output_loss: 0.5250 - val_aux_output_loss: 0.7520\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4523 - main_output_loss: 0.4217 - aux_output_loss: 0.7303 - val_loss: 0.5102 - val_main_output_loss: 0.4850 - val_aux_output_loss: 0.7379\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4493 - main_output_loss: 0.4188 - aux_output_loss: 0.7225 - val_loss: 0.5432 - val_main_output_loss: 0.5209 - val_aux_output_loss: 0.7427\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4469 - main_output_loss: 0.4170 - aux_output_loss: 0.7155 - val_loss: 0.4761 - val_main_output_loss: 0.4499 - val_aux_output_loss: 0.7130\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4445 - main_output_loss: 0.4150 - aux_output_loss: 0.7093 - val_loss: 0.5125 - val_main_output_loss: 0.4895 - val_aux_output_loss: 0.7191\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4424 - main_output_loss: 0.4134 - aux_output_loss: 0.7030 - val_loss: 0.5336 - val_main_output_loss: 0.5129 - val_aux_output_loss: 0.7198\n",
      "5160/5160 [==============================] - 0s 19us/sample - loss: 0.4481 - main_output_loss: 0.4220 - aux_output_loss: 0.6964\n",
      "0.44813263425531313 0.42195964 0.69643533\n",
      "[[1.7942412]\n",
      " [2.8267808]\n",
      " [1.2086037]] [[2.109439 ]\n",
      " [2.335369 ]\n",
      " [1.3111105]]\n"
     ]
    }
   ],
   "source": [
    "main_output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model4 = keras.Model(inputs=[input_A, input_B], outputs=[main_output, aux_output])\n",
    "model4.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model4.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model4.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model4.predict([X_new_A, X_new_B])\n",
    "print(total_loss, main_loss, aux_loss)\n",
    "print(y_pred_main, y_pred_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f1bd00a6198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 2.6605 - output_1_loss: 2.3883 - output_2_loss: 5.1018 - val_loss: 3.1175 - val_output_1_loss: 2.8633 - val_output_2_loss: 5.3986\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 1.0803 - output_1_loss: 0.8150 - output_2_loss: 3.4674 - val_loss: 1.2949 - val_output_1_loss: 0.9618 - val_output_2_loss: 4.2915\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.8427 - output_1_loss: 0.6745 - output_2_loss: 2.3572 - val_loss: 0.9592 - val_output_1_loss: 0.6801 - val_output_2_loss: 3.4682\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.7407 - output_1_loss: 0.6212 - output_2_loss: 1.8142 - val_loss: 0.8397 - val_output_1_loss: 0.6151 - val_output_2_loss: 2.8600\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6876 - output_1_loss: 0.5917 - output_2_loss: 1.5490 - val_loss: 0.7755 - val_output_1_loss: 0.5978 - val_output_2_loss: 2.3740\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6552 - output_1_loss: 0.5705 - output_2_loss: 1.4159 - val_loss: 0.7327 - val_output_1_loss: 0.5862 - val_output_2_loss: 2.0526\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6314 - output_1_loss: 0.5524 - output_2_loss: 1.3409 - val_loss: 0.6908 - val_output_1_loss: 0.5657 - val_output_2_loss: 1.8162\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6133 - output_1_loss: 0.5377 - output_2_loss: 1.2925 - val_loss: 0.6758 - val_output_1_loss: 0.5722 - val_output_2_loss: 1.6100\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5966 - output_1_loss: 0.5234 - output_2_loss: 1.2548 - val_loss: 0.6451 - val_output_1_loss: 0.5514 - val_output_2_loss: 1.4881\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5817 - output_1_loss: 0.5101 - output_2_loss: 1.2247 - val_loss: 0.6294 - val_output_1_loss: 0.5448 - val_output_2_loss: 1.3900\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5684 - output_1_loss: 0.4986 - output_2_loss: 1.1969 - val_loss: 0.6023 - val_output_1_loss: 0.5227 - val_output_2_loss: 1.3195\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5569 - output_1_loss: 0.4888 - output_2_loss: 1.1703 - val_loss: 0.5879 - val_output_1_loss: 0.5135 - val_output_2_loss: 1.2578\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5459 - output_1_loss: 0.4793 - output_2_loss: 1.1456 - val_loss: 0.5679 - val_output_1_loss: 0.4959 - val_output_2_loss: 1.2162\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5366 - output_1_loss: 0.4715 - output_2_loss: 1.1215 - val_loss: 0.5554 - val_output_1_loss: 0.4865 - val_output_2_loss: 1.1760\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5279 - output_1_loss: 0.4644 - output_2_loss: 1.0987 - val_loss: 0.5444 - val_output_1_loss: 0.4783 - val_output_2_loss: 1.1399\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5197 - output_1_loss: 0.4580 - output_2_loss: 1.0753 - val_loss: 0.5357 - val_output_1_loss: 0.4723 - val_output_2_loss: 1.1055\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5121 - output_1_loss: 0.4519 - output_2_loss: 1.0527 - val_loss: 0.5248 - val_output_1_loss: 0.4631 - val_output_2_loss: 1.0804\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5053 - output_1_loss: 0.4468 - output_2_loss: 1.0311 - val_loss: 0.5151 - val_output_1_loss: 0.4554 - val_output_2_loss: 1.0524\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4992 - output_1_loss: 0.4426 - output_2_loss: 1.0094 - val_loss: 0.5070 - val_output_1_loss: 0.4488 - val_output_2_loss: 1.0296\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4931 - output_1_loss: 0.4381 - output_2_loss: 0.9873 - val_loss: 0.5024 - val_output_1_loss: 0.4469 - val_output_2_loss: 1.0006\n",
      "5160/5160 [==============================] - 0s 18us/sample - loss: 0.4959 - output_1_loss: 0.4434 - output_2_loss: 0.9752\n",
      "0.49589378223862757 0.44343236 0.9751759\n",
      "[[1.7571504]\n",
      " [2.8326354]\n",
      " [1.1302142]] [[2.0910418]\n",
      " [2.3024797]\n",
      " [1.6514804]]\n"
     ]
    }
   ],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model5 = WideAndDeepModel()\n",
    "model5.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "main_output, aux_output = model5(inputs=[input_A, input_B])\n",
    "history = model5.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                     validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model5.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model5.predict([X_new_A, X_new_B])\n",
    "print(total_loss, main_loss, aux_loss)\n",
    "print(y_pred_main, y_pred_aux)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
