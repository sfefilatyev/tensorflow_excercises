{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 94us/sample - loss: 0.8647 - val_loss: 0.6349\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.7946 - val_loss: 1.4549\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.7536 - val_loss: 0.5054\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4650 - val_loss: 0.4839\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4532 - val_loss: 0.4758\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4400 - val_loss: 0.4595\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4298 - val_loss: 0.4542\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4275 - val_loss: 0.4445\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4206 - val_loss: 0.4385\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4128 - val_loss: 0.4300\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4092 - val_loss: 0.4299\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4037 - val_loss: 0.4213\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3998 - val_loss: 0.4220\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3973 - val_loss: 0.4106\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3927 - val_loss: 0.4070\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3904 - val_loss: 0.4118\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3909 - val_loss: 0.4076\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3864 - val_loss: 0.4083\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3848 - val_loss: 0.3959\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3821 - val_loss: 0.3979\n",
      "5160/5160 [==============================] - 0s 12us/sample - loss: 0.3774\n",
      "[[0.79855675]\n",
      " [0.9069952 ]\n",
      " [1.9719923 ]]\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 38)           0           input_2[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            39          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 1.0041 - val_loss: 0.5793\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4896 - val_loss: 0.4685\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4342 - val_loss: 0.4295\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4150 - val_loss: 0.4070\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3981 - val_loss: 0.3933\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3992 - val_loss: 0.3812\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3820 - val_loss: 0.3793\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3721 - val_loss: 0.3700\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3700 - val_loss: 0.3593\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3503 - val_loss: 0.3597\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3542 - val_loss: 0.3474\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3418 - val_loss: 0.3478\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3492 - val_loss: 0.3379\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3437 - val_loss: 0.3362\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3247 - val_loss: 0.3353\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3363 - val_loss: 0.3302\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3206 - val_loss: 0.3325\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3187 - val_loss: 0.3278\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3123 - val_loss: 0.3226\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3141 - val_loss: 0.3196\n",
      "5160/5160 [==============================] - 0s 14us/sample - loss: 0.3036\n",
      "[[0.8494529 ]\n",
      " [0.48428106]\n",
      " [2.1107152 ]]\n"
     ]
    }
   ],
   "source": [
    "# Wide and deep neural net.\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model2 = keras.Model(inputs=[input_], outputs=[output])\n",
    "model2.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(model2.summary())\n",
    "history2 = model2.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test2 = model2.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model2.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 1.9651 - val_loss: 0.8567\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.7392 - val_loss: 0.7320\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.6713 - val_loss: 0.6932\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.6390 - val_loss: 0.6658\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.6131 - val_loss: 0.6418\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5921 - val_loss: 0.6238\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5727 - val_loss: 0.6043\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5586 - val_loss: 0.5912\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5443 - val_loss: 0.5782\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5342 - val_loss: 0.5662\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5245 - val_loss: 0.5563\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5147 - val_loss: 0.5497\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5062 - val_loss: 0.5393\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5005 - val_loss: 0.5421\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4950 - val_loss: 0.5284\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4915 - val_loss: 0.5239\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4874 - val_loss: 0.5241\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4841 - val_loss: 0.5165\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4803 - val_loss: 0.5172\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4781 - val_loss: 0.5160\n",
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.4717\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model3 = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model3.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model3.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model3.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model3.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f02e82e5f28>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f02b073e240>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f02b07a2c88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f02b073e860>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x7f02b073ecf8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f02b073edd8>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f02b073e240>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_12'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.get_layer('dense_12') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 1.1455 - main_output_loss: 1.0176 - aux_output_loss: 2.2944 - val_loss: 0.6432 - val_main_output_loss: 0.5613 - val_aux_output_loss: 1.3784\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5632 - main_output_loss: 0.5097 - aux_output_loss: 1.0443 - val_loss: 0.5633 - val_main_output_loss: 0.5187 - val_aux_output_loss: 0.9642\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.5232 - main_output_loss: 0.4840 - aux_output_loss: 0.8760 - val_loss: 0.5434 - val_main_output_loss: 0.5044 - val_aux_output_loss: 0.8937\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5096 - main_output_loss: 0.4728 - aux_output_loss: 0.8397 - val_loss: 0.5349 - val_main_output_loss: 0.4973 - val_aux_output_loss: 0.8720\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5016 - main_output_loss: 0.4657 - aux_output_loss: 0.8238 - val_loss: 0.5276 - val_main_output_loss: 0.4906 - val_aux_output_loss: 0.8588\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4956 - main_output_loss: 0.4603 - aux_output_loss: 0.8118 - val_loss: 0.5219 - val_main_output_loss: 0.4855 - val_aux_output_loss: 0.8489\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4907 - main_output_loss: 0.4560 - aux_output_loss: 0.8031 - val_loss: 0.5177 - val_main_output_loss: 0.4819 - val_aux_output_loss: 0.8395\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4866 - main_output_loss: 0.4524 - aux_output_loss: 0.7933 - val_loss: 0.5136 - val_main_output_loss: 0.4781 - val_aux_output_loss: 0.8327\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4831 - main_output_loss: 0.4495 - aux_output_loss: 0.7855 - val_loss: 0.5099 - val_main_output_loss: 0.4750 - val_aux_output_loss: 0.8245\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4802 - main_output_loss: 0.4469 - aux_output_loss: 0.7786 - val_loss: 0.5078 - val_main_output_loss: 0.4733 - val_aux_output_loss: 0.8173\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4771 - main_output_loss: 0.4446 - aux_output_loss: 0.7700 - val_loss: 0.5050 - val_main_output_loss: 0.4709 - val_aux_output_loss: 0.8108\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4744 - main_output_loss: 0.4423 - aux_output_loss: 0.7631 - val_loss: 0.5047 - val_main_output_loss: 0.4714 - val_aux_output_loss: 0.8046\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4726 - main_output_loss: 0.4409 - aux_output_loss: 0.7564 - val_loss: 0.5000 - val_main_output_loss: 0.4669 - val_aux_output_loss: 0.7963\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4701 - main_output_loss: 0.4390 - aux_output_loss: 0.7496 - val_loss: 0.4977 - val_main_output_loss: 0.4653 - val_aux_output_loss: 0.7885\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4681 - main_output_loss: 0.4375 - aux_output_loss: 0.7427 - val_loss: 0.4961 - val_main_output_loss: 0.4641 - val_aux_output_loss: 0.7824\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4664 - main_output_loss: 0.4363 - aux_output_loss: 0.7366 - val_loss: 0.4936 - val_main_output_loss: 0.4623 - val_aux_output_loss: 0.7758\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4644 - main_output_loss: 0.4348 - aux_output_loss: 0.7306 - val_loss: 0.4916 - val_main_output_loss: 0.4607 - val_aux_output_loss: 0.7689\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4626 - main_output_loss: 0.4334 - aux_output_loss: 0.7251 - val_loss: 0.4905 - val_main_output_loss: 0.4602 - val_aux_output_loss: 0.7636\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4612 - main_output_loss: 0.4326 - aux_output_loss: 0.7184 - val_loss: 0.4876 - val_main_output_loss: 0.4581 - val_aux_output_loss: 0.7569\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4595 - main_output_loss: 0.4315 - aux_output_loss: 0.7129 - val_loss: 0.4855 - val_main_output_loss: 0.4561 - val_aux_output_loss: 0.7513\n",
      "5160/5160 [==============================] - 0s 25us/sample - loss: 0.4557 - main_output_loss: 0.4250 - aux_output_loss: 0.7177\n",
      "0.4556823867004971 0.42498252 0.7176885\n",
      "[[0.7574731]\n",
      " [1.0494581]\n",
      " [2.1437614]] [[1.2823024]\n",
      " [1.0909685]\n",
      " [2.528014 ]]\n"
     ]
    }
   ],
   "source": [
    "main_output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model4 = keras.Model(inputs=[input_A, input_B], outputs=[main_output, aux_output])\n",
    "model4.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model4.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model4.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model4.predict([X_new_A, X_new_B])\n",
    "print(total_loss, main_loss, aux_loss)\n",
    "print(y_pred_main, y_pred_aux)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
