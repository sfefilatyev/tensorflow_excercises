{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sfefilatyev/projects/tensorflow_exercises/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 99us/sample - loss: 0.8779 - val_loss: 0.6241\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.5491 - val_loss: 0.5057\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6182 - val_loss: 0.5068\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4914 - val_loss: 0.4687\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4666 - val_loss: 0.4520\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4556 - val_loss: 0.4502\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4475 - val_loss: 0.4313\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4377 - val_loss: 0.4235\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4355 - val_loss: 0.4258\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4311 - val_loss: 0.4150\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4201 - val_loss: 0.4101\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4176 - val_loss: 0.4094\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4109 - val_loss: 0.4074\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4058 - val_loss: 0.3996\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4027 - val_loss: 0.3955\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4038 - val_loss: 0.3967\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4076 - val_loss: 0.3941\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3964 - val_loss: 0.3923\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3938 - val_loss: 0.3902\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3886 - val_loss: 0.4040\n",
      "5160/5160 [==============================] - 0s 11us/sample - loss: 0.4235\n",
      "[[1.1833265]\n",
      " [1.8454115]\n",
      " [1.5643709]]\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 38)           0           input_2[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            39          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 1.2142 - val_loss: 0.6063\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5164 - val_loss: 0.4462\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4153 - val_loss: 0.3911\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3914 - val_loss: 0.3703\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3833 - val_loss: 0.3558\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3578 - val_loss: 0.3542\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3479 - val_loss: 0.3364\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3423 - val_loss: 0.3260\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3479 - val_loss: 0.3219\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3251 - val_loss: 0.3165\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3195 - val_loss: 0.3107\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3185 - val_loss: 0.3132\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3131 - val_loss: 0.3035\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3149 - val_loss: 0.3056\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3010 - val_loss: 0.3041\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.2995 - val_loss: 0.3108\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.2984 - val_loss: 0.2996\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.2989 - val_loss: 0.2971\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.2990 - val_loss: 0.2949\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2920 - val_loss: 0.2979\n",
      "5160/5160 [==============================] - 0s 13us/sample - loss: 0.3069\n",
      "[[0.8425557]\n",
      " [1.8803616]\n",
      " [1.6217322]]\n"
     ]
    }
   ],
   "source": [
    "# Wide and deep neural net.\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model2 = keras.Model(inputs=[input_], outputs=[output])\n",
    "model2.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(model2.summary())\n",
    "history2 = model2.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test2 = model2.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model2.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 1.3032 - val_loss: 0.5476\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5012 - val_loss: 0.4541\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4433 - val_loss: 0.4154\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4198 - val_loss: 0.3935\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4034 - val_loss: 0.3880\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3952 - val_loss: 0.3952\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3831 - val_loss: 0.3731\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3782 - val_loss: 0.3640\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3763 - val_loss: 0.3603\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3606 - val_loss: 0.3381\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3555 - val_loss: 0.3332\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3552 - val_loss: 0.3277\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3465 - val_loss: 0.3350\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3518 - val_loss: 0.3306\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3437 - val_loss: 0.3210\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3362 - val_loss: 0.3178\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3333 - val_loss: 0.3189\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3343 - val_loss: 0.3278\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3388 - val_loss: 0.3154\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3332 - val_loss: 0.3124\n",
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.3305\n"
     ]
    }
   ],
   "source": [
    "# Wide and deep network with auxilliary output\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model3 = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model3.compile(loss=\"mse\", optimizer=\"Adam\") # optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model3.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model3.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model3.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f6c28267fd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f6c282bf2e8>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f6c2826e048>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f6c2826e2e8>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x7f6c2826ebe0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f6c2826ecc0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f6c282bf2e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model3.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_8'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.get_layer('dense_8') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 28us/sample - loss: 0.5064 - main_output_loss: 0.4723 - aux_output_loss: 0.8139\n",
      "0.5064139545425889 0.47233632 0.8139463\n",
      "[[0.8056086]\n",
      " [1.8225387]\n",
      " [1.5147371]] [[1.2959085]\n",
      " [2.042921 ]\n",
      " [1.7641346]]\n"
     ]
    }
   ],
   "source": [
    "# Saving and restoring model\n",
    "import os\n",
    "if os.path.exists(\"model4.hdf5\"):\n",
    "    model4 = keras.models.load_model(\"model4.hdf5\")\n",
    "else:\n",
    "    main_output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "    aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "    model4 = keras.Model(inputs=[input_A, input_B], outputs=[main_output, aux_output])\n",
    "    model4.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "    history = model4.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                        validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model4.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model4.predict([X_new_A, X_new_B])\n",
    "print(total_loss, main_loss, aux_loss)\n",
    "print(y_pred_main, y_pred_aux)\n",
    "if not os.path.exists(\"model4.hdf5\"):\n",
    "    model4.save(\"model4.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f6c502f5748>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f6c502f5748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f6c502f5748>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method WideAndDeepModel.call of <__main__.WideAndDeepModel object at 0x7f6c502f5748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 3.2018 - output_1_loss: 2.9056 - output_2_loss: 5.8599 - val_loss: 1.7419 - val_output_1_loss: 1.3326 - val_output_2_loss: 5.4234\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 1.4021 - output_1_loss: 1.0525 - output_2_loss: 4.5475 - val_loss: 1.1306 - val_output_1_loss: 0.8265 - val_output_2_loss: 3.8666\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.9926 - output_1_loss: 0.7423 - output_2_loss: 3.2456 - val_loss: 0.9116 - val_output_1_loss: 0.7001 - val_output_2_loss: 2.8179\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.8476 - output_1_loss: 0.6667 - output_2_loss: 2.4747 - val_loss: 0.8051 - val_output_1_loss: 0.6447 - val_output_2_loss: 2.2481\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.7734 - output_1_loss: 0.6303 - output_2_loss: 2.0640 - val_loss: 0.7481 - val_output_1_loss: 0.6154 - val_output_2_loss: 1.9414\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.7321 - output_1_loss: 0.6097 - output_2_loss: 1.8352 - val_loss: 0.7134 - val_output_1_loss: 0.5959 - val_output_2_loss: 1.7699\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.7042 - output_1_loss: 0.5941 - output_2_loss: 1.6950 - val_loss: 0.6857 - val_output_1_loss: 0.5770 - val_output_2_loss: 1.6631\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6824 - output_1_loss: 0.5804 - output_2_loss: 1.6021 - val_loss: 0.6665 - val_output_1_loss: 0.5637 - val_output_2_loss: 1.5921\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6649 - output_1_loss: 0.5681 - output_2_loss: 1.5355 - val_loss: 0.6522 - val_output_1_loss: 0.5534 - val_output_2_loss: 1.5405\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6516 - output_1_loss: 0.5586 - output_2_loss: 1.4878 - val_loss: 0.6380 - val_output_1_loss: 0.5423 - val_output_2_loss: 1.5000\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6398 - output_1_loss: 0.5498 - output_2_loss: 1.4492 - val_loss: 0.6289 - val_output_1_loss: 0.5356 - val_output_2_loss: 1.4684\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6314 - output_1_loss: 0.5438 - output_2_loss: 1.4190 - val_loss: 0.6196 - val_output_1_loss: 0.5283 - val_output_2_loss: 1.4400\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6240 - output_1_loss: 0.5388 - output_2_loss: 1.3929 - val_loss: 0.6099 - val_output_1_loss: 0.5203 - val_output_2_loss: 1.4165\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6158 - output_1_loss: 0.5321 - output_2_loss: 1.3702 - val_loss: 0.6020 - val_output_1_loss: 0.5139 - val_output_2_loss: 1.3941\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6082 - output_1_loss: 0.5258 - output_2_loss: 1.3492 - val_loss: 0.5997 - val_output_1_loss: 0.5136 - val_output_2_loss: 1.3737\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6047 - output_1_loss: 0.5241 - output_2_loss: 1.3303 - val_loss: 0.5918 - val_output_1_loss: 0.5070 - val_output_2_loss: 1.3556\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5957 - output_1_loss: 0.5161 - output_2_loss: 1.3129 - val_loss: 0.5844 - val_output_1_loss: 0.5006 - val_output_2_loss: 1.3376\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5938 - output_1_loss: 0.5157 - output_2_loss: 1.2955 - val_loss: 0.5812 - val_output_1_loss: 0.4990 - val_output_2_loss: 1.3209\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5860 - output_1_loss: 0.5089 - output_2_loss: 1.2796 - val_loss: 0.5765 - val_output_1_loss: 0.4955 - val_output_2_loss: 1.3045\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5864 - output_1_loss: 0.5109 - output_2_loss: 1.2644 - val_loss: 0.5703 - val_output_1_loss: 0.4906 - val_output_2_loss: 1.2885\n",
      "5160/5160 [==============================] - 0s 20us/sample - loss: 0.5920 - output_1_loss: 0.5158 - output_2_loss: 1.2709\n",
      "0.5919965182163919 0.5157992 1.2709078\n",
      "[[0.6978   ]\n",
      " [1.8509033]\n",
      " [1.7407099]] [[2.1608396]\n",
      " [1.9583204]\n",
      " [1.993948 ]]\n"
     ]
    }
   ],
   "source": [
    "# Subclassing-API model\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model5 = WideAndDeepModel()\n",
    "model5.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "main_output, aux_output = model5(inputs=[input_A, input_B])\n",
    "history = model5.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                     validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model5.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model5.predict([X_new_A, X_new_B])\n",
    "print(total_loss, main_loss, aux_loss)\n",
    "print(y_pred_main, y_pred_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 1.7408 - val_loss: 0.7575\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.7029 - val_loss: 0.5213\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5171 - val_loss: 0.4578\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4521 - val_loss: 0.4123\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4120 - val_loss: 0.3845\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3861 - val_loss: 0.3637\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3708 - val_loss: 0.3561\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3593 - val_loss: 0.3417\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3510 - val_loss: 0.3419\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3468 - val_loss: 0.3338\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3463 - val_loss: 0.3326\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3410 - val_loss: 0.3341\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3380 - val_loss: 0.3301\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3375 - val_loss: 0.3319\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3412 - val_loss: 0.3344\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3381 - val_loss: 0.3243\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3351 - val_loss: 0.3269\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3334 - val_loss: 0.3264\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3311 - val_loss: 0.3204\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3283 - val_loss: 0.3206\n",
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.3300\n"
     ]
    }
   ],
   "source": [
    "# Using callbacks\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model6 = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model6.compile(loss=\"mse\", optimizer=\"Adam\")\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model6.h5\", save_best_only=True)\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model6.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid), callbacks=[checkpoint_cb])\n",
    "mse_test = model6.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model6.predict((X_new_A, X_new_B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
